{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets.davis import DAVISPairDataset\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--root\", help='path to DAVIS-like folder')\n",
    "parser.add_argument(\"--anno\", default=\"Annotations\",\n",
    "                    help='path to Annotations subfolder (of ROOT)')\n",
    "parser.add_argument(\"--jpeg\", default=\"JPEGImages\",\n",
    "                    help='path to JPEGImages subfolder (of ROOT)')\n",
    "parser.add_argument(\"--res\", default=\"480p\",\n",
    "                    help='path to Resolution subfolder (of ANNO and JPEG)')\n",
    "parser.add_argument(\"--imgset\", default=\"ImageSets\",\n",
    "                    help='path to ImageSet subfolder (of ROOT)')\n",
    "parser.add_argument(\"--year\", default=\"2017\",\n",
    "                    help='path to Year subfolder (of IMGSET)')\n",
    "parser.add_argument(\"--phase\", default=\"train\",\n",
    "                    help='path to phase txt file (of IMGSET/YEAR)')\n",
    "parser.add_argument(\"--mode\", default=0, type=int,\n",
    "                    help='frame pair selector mode')\n",
    "args = parser.parse_args('--root data/DAVIS-trainval --res 480p_split --mode 1'.split())\n",
    "\n",
    "dataset = DAVISPairDataset(root_path=args.root,\n",
    "                           annotation_folder=args.anno,\n",
    "                           jpeg_folder=args.jpeg,\n",
    "                           resolution=args.res,\n",
    "                           imageset_folder=args.imgset,\n",
    "                           year=args.year,\n",
    "                           phase=args.phase,\n",
    "                           mode=args.mode)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    for support_img, support_anno, query_img, query_anno in zip(*batch[0], batch[1]):\n",
    "        fig, ax = plt.subplots(2, 2)\n",
    "        ax[0, 0].imshow(support_img.permute(1, 2, 0))\n",
    "        ax[0, 1].imshow(support_anno.squeeze())\n",
    "        ax[1, 0].imshow(query_img.permute(1, 2, 0))\n",
    "        ax[1, 1].imshow(query_anno.squeeze())\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.getter import get_instance, get_data\n",
    "from utils.device import move_to\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--weight')\n",
    "parser.add_argument('--gpus', default=None)\n",
    "args = parser.parse_args('--weight runs/UNet_Single-2020_05_03-04_23_34/best_loss.pth'.split())\n",
    "\n",
    "dev_id = 'cuda:{}'.format(args.gpus) \\\n",
    "    if torch.cuda.is_available() and args.gpus is not None \\\n",
    "    else 'cpu'\n",
    "device = torch.device(dev_id)\n",
    "\n",
    "config = torch.load(args.weight, map_location=dev_id)\n",
    "\n",
    "model = get_instance(config['config']['model']).to(device)\n",
    "model.load_state_dict(config['model_state_dict'])\n",
    "\n",
    "_, dataloader = get_data(config['config']['dataset'],\n",
    "                         config['config']['seed'])\n",
    "\n",
    "def visualize_attention(m, i, o):\n",
    "    _, _, H, W = i[0].shape\n",
    "    attns = m.attn_score.mean(dim=1).reshape(-1, H, W).cpu()\n",
    "    for attn in attns:\n",
    "        plt.imshow(attn, vmin=0.0)\n",
    "model.middle_conv.register_forward_hook(visualize_attention)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        output = model(move_to(batch[0], device))\n",
    "        preds = torch.argmax(output, dim=1).cpu()\n",
    "        for support_img, support_anno, query_img, query_anno, pred in zip(*batch[0], batch[1], preds):\n",
    "            print('=' * 60)\n",
    "\n",
    "            fig, ax = plt.subplots(2, 2)\n",
    "            ax[0, 0].imshow(support_img.permute(1, 2, 0))\n",
    "            ax[0, 0].imshow(support_anno.squeeze(0), alpha=0.2)\n",
    "            ax[0, 0].set_title('Reference frame + GT')\n",
    "            \n",
    "            ax[1, 0].imshow(query_img.permute(1, 2, 0))\n",
    "            ax[1, 0].imshow(pred.squeeze(0), alpha=0.2)\n",
    "            ax[1, 0].set_title('Query frame + Pred')\n",
    "            \n",
    "            ax[0, 1].imshow((query_anno & ~pred).squeeze(0))\n",
    "            ax[0, 1].set_title('False Negative')\n",
    "            ax[1, 1].imshow((~query_anno & pred).squeeze(0))\n",
    "            ax[1, 1].set_title('False Positive')\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "\n",
    "from utils.getter import get_instance, get_data\n",
    "from utils.device import move_to\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--weight')\n",
    "parser.add_argument('--gpus', default=None)\n",
    "args = parser.parse_args('--weight backup/STMWithSTN-2020_05_11-22_43_49/best_loss.pth --gpus 0'.split())\n",
    "\n",
    "dev_id = 'cuda:{}'.format(args.gpus) \\\n",
    "    if torch.cuda.is_available() and args.gpus is not None \\\n",
    "    else 'cpu'\n",
    "device = torch.device(dev_id)\n",
    "\n",
    "config = torch.load(args.weight, map_location=dev_id)\n",
    "\n",
    "model = get_instance(config['config']['model']).to(device)\n",
    "model.load_state_dict(config['model_state_dict'])\n",
    "\n",
    "config['config']['dataset']['val']['loader']['args']['shuffle'] = True\n",
    "# config['config']['dataset']['val']['args']['shuffle'] = True\n",
    "_, dataloader = get_data(config['config']['dataset'],\n",
    "                         config['config']['seed'])\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     for idx, batch in enumerate(dataloader):\n",
    "#         a_im, a_seg, b_im, c_im, nobjs = batch[0]\n",
    "#         c_seg = batch[1]\n",
    "        \n",
    "#         a_seg = F.one_hot(a_seg, 11).permute(0, 3, 1, 2)\n",
    "#         a_im_stn = model.stn(a_im, a_seg)\n",
    "        \n",
    "#         fig, ax = plt.subplots(3, 1)\n",
    "#         ax[0].imshow(a_im[0].permute(1, 2, 0))\n",
    "#         ax[1].imshow(a_im_stn[0].permute(1, 2, 0))\n",
    "#         ax[2].imshow(torch.abs(a_im[0] - a_im_stn[0]).mean(0))\n",
    "#         plt.show()\n",
    "#         plt.close()\n",
    "# #         output = model.stn(move_to(batch[0], device))\n",
    "# #         break\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        output = model(move_to(batch[0], device))\n",
    "        preds = torch.argmax(output, dim=1).cpu()\n",
    "        for support_img, support_anno, _, query_img, nobjs, query_anno, pred in zip(*batch[0], batch[1], preds):\n",
    "            print('=' * 60)\n",
    "\n",
    "            fig, ax = plt.subplots(2, 2)\n",
    "            ax[0, 0].imshow(support_img.permute(1, 2, 0))\n",
    "            ax[0, 0].imshow(support_anno.squeeze(0), alpha=0.2)\n",
    "            ax[0, 0].set_title('Reference frame + GT')\n",
    "            \n",
    "            ax[1, 0].imshow(query_img.permute(1, 2, 0))\n",
    "            ax[1, 0].imshow(pred.squeeze(0), alpha=0.2)\n",
    "            ax[1, 0].set_title('Query frame + Pred')\n",
    "            \n",
    "            ax[0, 1].imshow((query_anno & ~pred).squeeze(0))\n",
    "            ax[0, 1].set_title('False Negative')\n",
    "            ax[1, 1].imshow((~query_anno & pred).squeeze(0))\n",
    "            ax[1, 1].set_title('False Positive')\n",
    "\n",
    "            fig.tight_layout()\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "video_name = 'deer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"viz/STM_DAVIS_17test-dev_/deer.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(f'viz/STM_DAVIS_17test-dev_/{video_name}.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"viz/STM_DAVIS_17test-dev/deer.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(f'viz/STM_DAVIS_17test-dev/{video_name}.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vltanh",
   "language": "python",
   "name": "vltanh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
